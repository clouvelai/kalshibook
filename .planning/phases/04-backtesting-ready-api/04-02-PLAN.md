---
phase: 04-backtesting-ready-api
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/collector/models.py
  - src/collector/processor.py
  - src/collector/writer.py
  - src/collector/main.py
  - src/collector/discovery.py
  - src/collector/enrichment.py
  - src/shared/config.py
  - src/shared/db.py
autonomous: true

must_haves:
  truths:
    - "Collector subscribes to the 'trade' WS channel without market_tickers filter (receives ALL public trades)"
    - "Trade messages are parsed, buffered, and batch-written to the trades table"
    - "Settlement data is captured when lifecycle 'determined' events arrive and enriched via Kalshi REST API"
    - "Event and series metadata is fetched from Kalshi REST API on market discovery and stored in events/series tables"
    - "Enrichment REST calls are async fire-and-forget (do not block the WS message loop)"
    - "Partition function is invoked for trades table alongside deltas"
  artifacts:
    - path: "src/collector/models.py"
      provides: "TradeExecution dataclass"
      contains: "TradeExecution"
    - path: "src/collector/enrichment.py"
      provides: "KalshiRestClient for market/event/series REST enrichment"
      contains: "KalshiRestClient"
    - path: "src/collector/writer.py"
      provides: "trade_buffer, settlement_buffer, _flush_trades, _flush_settlements"
      contains: "_flush_trades"
    - path: "src/collector/main.py"
      provides: "Trade channel subscription and trade message routing"
      contains: "trade"
  key_links:
    - from: "src/collector/main.py"
      to: "src/collector/writer.py"
      via: "trade messages routed through writer.add_trade"
      pattern: "add_trade"
    - from: "src/collector/main.py"
      to: "src/collector/enrichment.py"
      via: "enrichment client initialized and used for REST API calls"
      pattern: "KalshiRestClient"
    - from: "src/collector/discovery.py"
      to: "src/collector/enrichment.py"
      via: "lifecycle events trigger enrichment calls"
      pattern: "enrich"
---

<objective>
Extend the collector to capture public trade executions, settlement data, and event/series hierarchy metadata.

Purpose: The collector currently captures only orderbook data. Backtesting requires trade execution data (what actually traded), settlement outcomes (how markets resolved), and event hierarchy (which markets belong together). This plan adds all three data capture paths.

Output: Updated collector with trade WS subscription, Kalshi REST enrichment client, and settlement/event/series data capture.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-backtesting-ready-api/04-01-SUMMARY.md
@src/collector/main.py
@src/collector/models.py
@src/collector/processor.py
@src/collector/writer.py
@src/collector/discovery.py
@src/collector/connection.py
@src/shared/config.py
@src/shared/db.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add TradeExecution model and extend writer with trade/settlement buffers</name>
  <files>
    src/collector/models.py
    src/collector/writer.py
    src/shared/db.py
  </files>
  <action>
**src/collector/models.py** -- Add `TradeExecution` dataclass following the existing frozen/slots pattern:
```python
@dataclass(frozen=True, slots=True)
class TradeExecution:
    """Parsed trade message from Kalshi WS."""
    trade_id: str
    market_ticker: str
    yes_price: int       # cents
    no_price: int        # cents
    count: int           # contracts traded
    taker_side: str      # "yes" or "no"
    ts: datetime
```

Also add a `SettlementRecord` dataclass for settlement data:
```python
@dataclass(frozen=True, slots=True)
class SettlementData:
    """Settlement/resolution data for a market."""
    market_ticker: str
    event_ticker: str
    result: str | None        # 'yes', 'no', 'all_no', 'all_yes', 'void'
    settlement_value: int | None  # cents
    determined_at: datetime | None
    settled_at: datetime | None
    source: str               # 'lifecycle', 'rest_api'
    metadata: dict | None
```

**src/collector/writer.py** -- Extend `DatabaseWriter`:
1. Import `TradeExecution` and `SettlementData` from models
2. Add `_trade_buffer: list[TradeExecution]` and `_settlement_buffer: list[SettlementData]` to `__init__`
3. Add `async def add_trade(self, trade: TradeExecution)` -- same pattern as `add_delta` (buffer + flush at max_batch_size)
4. Add `async def add_settlement(self, settlement: SettlementData)` -- buffer + immediate flush (settlements are low-volume, don't need batching threshold)
5. Add `_flush_trades()` -- batch INSERT into trades table, same pattern as `_flush_deltas` including `_ensure_trade_partition` for on-demand partition creation
6. Add `_flush_settlements()` -- UPSERT into settlements table (ON CONFLICT (market_ticker) DO UPDATE to handle re-enrichment)
7. Add `_ensure_trade_partition()` -- static method, identical pattern to `_ensure_delta_partition` but for `trades` table (partition name: `trades_YYYY_MM_DD`)
8. Update `flush_all()` to include trade and settlement buffers
9. Update `buffer_sizes` property to include trades and settlements

**src/shared/db.py** -- Update `ensure_partitions` function: the SQL function call `create_future_partitions` already handles trades after Plan 01's migration update. No code change needed here (the function just calls the DB function). Verify this is the case -- if the DB function is already updated by migration 20260216000005, no Python changes needed.
  </action>
  <verify>
Run `python -c "from src.collector.models import TradeExecution, SettlementData; from src.collector.writer import DatabaseWriter; print('OK')"` to verify imports work.
  </verify>
  <done>TradeExecution and SettlementData models exist, writer has trade/settlement buffers with flush methods following the same batch-write pattern as deltas.</done>
</task>

<task type="auto">
  <name>Task 2: Create Kalshi REST enrichment client and wire collector for trade capture + enrichment</name>
  <files>
    src/collector/enrichment.py
    src/collector/main.py
    src/collector/discovery.py
    src/shared/config.py
  </files>
  <action>
**src/shared/config.py** -- Add Kalshi REST API base URL setting:
```python
kalshi_rest_base_url: str = "https://api.elections.kalshi.com/trade-api/v2"
```

**src/collector/enrichment.py** -- NEW FILE. Create `KalshiRestClient` class:
- Constructor takes `api_key_id: str`, `private_key`, `base_url: str`. Creates an `httpx.AsyncClient` with `base_url` and `timeout=10.0`.
- Implement `_generate_rest_headers(method: str, path: str) -> dict` using RSA-PSS signature (same key/algo as WS auth in connection.py). REST API signs `timestamp + method.upper() + path`. Use the same `padding.PSS` + `hashes.SHA256` pattern from `connection.py::generate_auth_headers`. Headers: `KALSHI-ACCESS-KEY`, `KALSHI-ACCESS-SIGNATURE`, `KALSHI-ACCESS-TIMESTAMP`.
- `async def get_market(self, ticker: str) -> dict | None` -- `GET /markets/{ticker}`, returns `resp.json().get("market")` on 200, `None` otherwise
- `async def get_event(self, event_ticker: str) -> dict | None` -- `GET /events/{event_ticker}`, returns `resp.json().get("event")` on 200
- `async def get_series(self, series_ticker: str) -> dict | None` -- `GET /series/{series_ticker}`, returns `resp.json().get("series")` on 200
- `async def close(self)` -- close the httpx client
- All methods: wrap in try/except, log errors with structlog, return None on failure. Do NOT raise -- enrichment failures should not crash the collector.

**src/collector/main.py** -- Extend `CollectorService`:
1. Import `TradeExecution` from models, `KalshiRestClient` from enrichment, `_parse_ts` from processor
2. In `__init__`: add `self._enrichment: KalshiRestClient | None = None`, add `self._fire_and_forget: set[asyncio.Task] = set()` for background task references (same GC protection pattern from deps.py)
3. In `start()`: initialize enrichment client: `self._enrichment = KalshiRestClient(settings.kalshi_api_key_id, self._private_key_for_rest, settings.kalshi_rest_base_url)`. Load private key using the same `load_private_key` from connection.py.
4. In `_handle_reconnect()`: after subscribing to `market_lifecycle_v2`, add: `await self._connection.send_subscribe(["trade"])` to subscribe to all public trades (no market_tickers filter).
5. In `_handle_message()`: add `elif msg_type == "trade": await self._handle_trade(msg)` routing
6. Add `async def _handle_trade(self, msg: dict)`: parse `msg["msg"]` fields (trade_id, market_ticker, yes_price, no_price, count, taker_side, ts), create `TradeExecution` using `_parse_ts` for timestamp, call `self._writer.add_trade(trade)`.
7. In `_cleanup()`: close enrichment client if initialized (`await self._enrichment.close()`)

**src/collector/discovery.py** -- Extend to trigger enrichment on lifecycle events:
1. Add an `on_enrichment_needed` callback attribute (same pattern as `on_market_update`)
2. In `handle_lifecycle_event`: after the market update callback, if event_type is in `TERMINAL_EVENT_TYPES` (specifically `determined` or `settled`), call `on_enrichment_needed` with the msg data to trigger settlement + event enrichment
3. Also when event_type is in `ACTIVE_EVENT_TYPES` (new market discovered), call `on_enrichment_needed` for event/series metadata enrichment

**src/collector/main.py** (continued) -- Wire enrichment:
1. Set `self._discovery.on_enrichment_needed = self._handle_enrichment_needed`
2. Add `async def _handle_enrichment_needed(self, data: dict)`: fire-and-forget task that calls `self._enrich_market(data)`. Use the `_fire_and_forget` set pattern:
```python
task = asyncio.create_task(self._enrich_market(data))
self._fire_and_forget.add(task)
task.add_done_callback(self._fire_and_forget.discard)
```
3. Add `async def _enrich_market(self, data: dict)`:
   - Extract ticker, event_ticker, event_type from data
   - If event_type in ('determined', 'settled'): call `self._enrichment.get_market(ticker)` to fetch settlement data. If result exists, create SettlementData and call `self._writer.add_settlement(...)`. Implement retry: if `result` field is None, wait 5 seconds and retry once (race condition with Kalshi API propagation).
   - Call `self._enrichment.get_event(event_ticker)` if event_ticker is present. Upsert result to events table via writer.
   - If event has `series_ticker`, call `self._enrichment.get_series(series_ticker)`. Upsert to series table via writer.
4. Add writer methods for event/series upserts: `add_event_update(data: dict)` and `add_series_update(data: dict)` to writer.py. These can be simple fire-and-forget DB operations (low volume).

**src/collector/writer.py** (additional methods):
- `async def add_event_update(self, data: dict)`: directly execute an UPSERT to events table (no buffering needed -- events are low-volume)
- `async def add_series_update(self, data: dict)`: directly execute an UPSERT to series table
- Also update the market upsert in `_flush_market_updates` to include `series_ticker` when available in the market data from enrichment.
  </action>
  <verify>
1. `python -c "from src.collector.enrichment import KalshiRestClient; print('OK')"` -- imports work
2. `python -c "from src.collector.main import CollectorService; print('OK')"` -- no circular imports
3. Verify `_handle_message` has trade routing
4. Verify `_handle_reconnect` subscribes to 'trade' channel
5. Verify enrichment methods are async and handle errors gracefully (no raise)
  </verify>
  <done>Collector subscribes to trade WS channel (all markets, no ticker filter), parses and buffers trade executions, captures settlement data on lifecycle events via REST enrichment, and stores event/series hierarchy metadata. All enrichment calls are async fire-and-forget to avoid blocking the WS message loop.</done>
</task>

</tasks>

<verification>
1. TradeExecution model matches Kalshi WS trade message format
2. Writer flushes trades with daily partition management
3. KalshiRestClient authenticates with same RSA-PSS as WS
4. Settlement enrichment retries once on empty result (propagation delay)
5. All REST calls are fire-and-forget (no WS loop blocking)
6. Trade channel subscription has NO market_tickers filter
7. No existing collector functionality broken
</verification>

<success_criteria>
- Collector starts, connects, subscribes to trade + lifecycle + orderbook channels
- Trade messages are parsed into TradeExecution and buffered/flushed to DB
- Lifecycle determined/settled events trigger REST enrichment for settlement data
- New market discovery triggers event/series REST enrichment
- All enrichment failures are logged but do not crash the collector
- Trades table partitions are created alongside delta partitions
</success_criteria>

<output>
After completion, create `.planning/phases/04-backtesting-ready-api/04-02-SUMMARY.md`
</output>
