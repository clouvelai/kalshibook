---
phase: 09-models-exceptions-and-http-transport
plan: 02
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - sdk/src/kalshibook/models.py
autonomous: true

must_haves:
  truths:
    - "Every API response shape has a corresponding frozen dataclass with attribute access"
    - "Timestamp fields are parsed to datetime objects (not raw ISO strings)"
    - "Field names match API JSON keys exactly (no renaming)"
    - "Credit metadata is accessible via response.meta.credits_used and response.meta.credits_remaining"
    - "ResponseMeta includes credits_used, credits_remaining, and response_time"
  artifacts:
    - path: "sdk/src/kalshibook/models.py"
      provides: "All SDK response dataclasses (~20 classes) with from_dict factories"
      contains: "class ResponseMeta"
  key_links:
    - from: "sdk/src/kalshibook/models.py"
      to: "sdk/src/kalshibook/_parsing.py"
      via: "import parse_datetime for timestamp conversion"
      pattern: "from kalshibook._parsing import parse_datetime"
    - from: "sdk/src/kalshibook/models.py"
      to: "src/api/models.py"
      via: "field names match API JSON keys exactly"
      pattern: "market_ticker|timestamp|snapshot_basis"
---

<objective>
Create all typed response dataclasses for the SDK -- one dataclass per API response shape, with `from_dict()` factory classmethods that convert raw JSON dicts into typed instances with datetime parsing.

Purpose: These models are what users interact with. Every client method in Phase 10 will return one of these dataclasses. IDE autocomplete, type checking, and the `.meta` credit tracking all depend on this module.

Output: A single `models.py` with ~20 frozen dataclasses covering every API endpoint response.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-models-exceptions-and-http-transport/09-RESEARCH.md
@sdk/src/kalshibook/models.py
@src/api/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement ResponseMeta and core data models (Orderbook, Delta, Trade)</name>
  <files>sdk/src/kalshibook/models.py</files>
  <action>
Replace the empty stub with the response model module. Use `@dataclass(slots=True, frozen=True)` on ALL dataclasses. Include `from __future__ import annotations` at top.

Import: `from kalshibook._parsing import parse_datetime`

**ResponseMeta** (credit/request metadata, attached to every response):
- `credits_used: int` (from X-Credits-Cost header -- this is the per-request cost)
- `credits_remaining: int` (from X-Credits-Remaining header)
- `response_time: float` (from response body)
- `request_id: str` (from response body or X-Request-ID header)
- `@classmethod from_headers(cls, headers: dict, body: dict) -> ResponseMeta` -- parses from httpx response headers and body. Use `.get()` with defaults: credits default to -1 (sentinel for "not present", e.g., on error responses), response_time defaults to 0.0, request_id defaults to "".

**OrderbookLevel**:
- `price: int`, `quantity: int`
- `from_dict(cls, data: dict) -> OrderbookLevel`

**OrderbookResponse**:
- `market_ticker: str`, `timestamp: datetime`, `snapshot_basis: datetime`, `deltas_applied: int`
- `yes: list[OrderbookLevel]`, `no: list[OrderbookLevel]`
- `meta: ResponseMeta`
- `from_dict(cls, data: dict, meta: ResponseMeta) -> OrderbookResponse`
- Parse timestamp and snapshot_basis via `parse_datetime()`

**DeltaRecord**:
- `market_ticker: str`, `ts: datetime`, `seq: int`, `price_cents: int`, `delta_amount: int`, `side: str`
- `from_dict(cls, data: dict) -> DeltaRecord`
- Parse `ts` via `parse_datetime()`

**DeltasResponse**:
- `data: list[DeltaRecord]`, `next_cursor: str | None`, `has_more: bool`, `meta: ResponseMeta`
- `from_dict(cls, data: dict, meta: ResponseMeta) -> DeltasResponse`

**TradeRecord**:
- `trade_id: str`, `market_ticker: str`, `yes_price: int`, `no_price: int`, `count: int`, `taker_side: str`, `ts: datetime`
- `from_dict(cls, data: dict) -> TradeRecord`
- Parse `ts` via `parse_datetime()`

**TradesResponse**:
- `data: list[TradeRecord]`, `next_cursor: str | None`, `has_more: bool`, `meta: ResponseMeta`
- `from_dict(cls, data: dict, meta: ResponseMeta) -> TradesResponse`

Key rules per locked decisions:
- Field names MUST match API JSON exactly (e.g., `ts` not `timestamp`, `price_cents` not `price`)
- All timestamp string fields become `datetime` via `parse_datetime()`
- `meta` is always the last field, passed separately (not from the data dict)
  </action>
  <verify>
Run: `cd /Users/samuelclark/Desktop/kalshibook && python -c "
from kalshibook.models import ResponseMeta, OrderbookLevel, OrderbookResponse, DeltaRecord, DeltasResponse, TradeRecord, TradesResponse
from datetime import datetime, timezone

meta = ResponseMeta.from_headers({'x-credits-cost': '5', 'x-credits-remaining': '95'}, {'response_time': 0.02, 'request_id': 'req_abc'})
assert meta.credits_used == 5
assert meta.credits_remaining == 95

level = OrderbookLevel.from_dict({'price': 65, 'quantity': 100})
assert level.price == 65

ob = OrderbookResponse.from_dict({
    'market_ticker': 'KXBTC-24',
    'timestamp': '2026-02-17T12:00:00Z',
    'snapshot_basis': '2026-02-17T11:00:00+00:00',
    'deltas_applied': 42,
    'yes': [{'price': 65, 'quantity': 100}],
    'no': [{'price': 35, 'quantity': 50}],
}, meta)
assert isinstance(ob.timestamp, datetime)
assert ob.meta.credits_used == 5

print('OK')
"`
  </verify>
  <done>ResponseMeta, OrderbookLevel, OrderbookResponse, DeltaRecord, DeltasResponse, TradeRecord, TradesResponse all importable and constructable from dicts with datetime parsing</done>
</task>

<task type="auto">
  <name>Task 2: Implement remaining models (Market, Event, Settlement, Candle, Billing)</name>
  <files>sdk/src/kalshibook/models.py</files>
  <action>
Add the remaining dataclasses to `models.py` (append after the trade models from Task 1).

**MarketSummary**:
- `ticker: str`, `title: str | None`, `event_ticker: str | None`, `status: str`, `category: str | None`
- `first_data_at: datetime | None`, `last_data_at: datetime | None`
- `from_dict(cls, data: dict) -> MarketSummary`
- Parse `first_data_at` and `last_data_at` via `parse_datetime()` (they can be None)

**MarketDetail** (NOT inheritance -- flat dataclass, includes all MarketSummary fields plus extras):
- All MarketSummary fields PLUS: `rules: str | None`, `strike_price: float | None`, `discovered_at: datetime`, `metadata: dict | None`, `snapshot_count: int`, `delta_count: int`
- `from_dict(cls, data: dict) -> MarketDetail`
- Parse `discovered_at`, `first_data_at`, `last_data_at` via `parse_datetime()`

Note: Do NOT use dataclass inheritance. The API server uses Pydantic inheritance (`MarketDetail(MarketSummary)`), but stdlib dataclasses handle inheritance poorly with `slots=True`. Use flat structures instead -- duplicate the shared fields.

**MarketsResponse**:
- `data: list[MarketSummary]`, `meta: ResponseMeta`
- `from_dict(cls, data: dict, meta: ResponseMeta) -> MarketsResponse`

**MarketDetailResponse**:
- `data: MarketDetail`, `meta: ResponseMeta`
- `from_dict(cls, data: dict, meta: ResponseMeta) -> MarketDetailResponse`

**CandleRecord**:
- `bucket: datetime`, `market_ticker: str`, `open: int`, `high: int`, `low: int`, `close: int`, `volume: int`, `trade_count: int`
- `from_dict(cls, data: dict) -> CandleRecord`
- Parse `bucket` via `parse_datetime()`

**CandlesResponse**:
- `data: list[CandleRecord]`, `meta: ResponseMeta`
- `from_dict(cls, data: dict, meta: ResponseMeta) -> CandlesResponse`

**SettlementRecord**:
- `market_ticker: str`, `event_ticker: str | None`, `result: str | None`, `settlement_value: int | None`
- `determined_at: datetime | None`, `settled_at: datetime | None`
- `from_dict(cls, data: dict) -> SettlementRecord`

**SettlementResponse**:
- `data: SettlementRecord`, `meta: ResponseMeta`
- `from_dict(cls, data: dict, meta: ResponseMeta) -> SettlementResponse`

**SettlementsResponse**:
- `data: list[SettlementRecord]`, `meta: ResponseMeta`
- `from_dict(cls, data: dict, meta: ResponseMeta) -> SettlementsResponse`

**EventSummary**:
- `event_ticker: str`, `series_ticker: str | None`, `title: str | None`, `sub_title: str | None`
- `category: str | None`, `mutually_exclusive: bool | None`, `status: str | None`, `market_count: int | None`
- `from_dict(cls, data: dict) -> EventSummary`

**EventDetail** (flat, NOT inheriting from EventSummary -- same reason as MarketDetail):
- All EventSummary fields PLUS: `markets: list[MarketSummary]`
- `from_dict(cls, data: dict) -> EventDetail`

**EventsResponse**:
- `data: list[EventSummary]`, `meta: ResponseMeta`
- `from_dict(cls, data: dict, meta: ResponseMeta) -> EventsResponse`

**EventDetailResponse**:
- `data: EventDetail`, `meta: ResponseMeta`
- `from_dict(cls, data: dict, meta: ResponseMeta) -> EventDetailResponse`

**BillingStatus** (for `client.usage()` method):
- `tier: str`, `credits_total: int`, `credits_used: int`, `credits_remaining: int`
- `payg_enabled: bool`, `billing_cycle_start: datetime`
- `from_dict(cls, data: dict) -> BillingStatus`
- Parse `billing_cycle_start` via `parse_datetime()`
  </action>
  <verify>
Run: `cd /Users/samuelclark/Desktop/kalshibook && python -c "
from kalshibook.models import (
    MarketSummary, MarketDetail, MarketsResponse, MarketDetailResponse,
    CandleRecord, CandlesResponse,
    SettlementRecord, SettlementResponse, SettlementsResponse,
    EventSummary, EventDetail, EventsResponse, EventDetailResponse,
    BillingStatus, ResponseMeta,
)
from datetime import datetime

# MarketSummary with optional datetime fields
ms = MarketSummary.from_dict({'ticker': 'KXBTC-24', 'title': 'BTC', 'event_ticker': None, 'status': 'active', 'category': 'Crypto', 'first_data_at': '2026-01-01T00:00:00Z', 'last_data_at': None})
assert isinstance(ms.first_data_at, datetime)
assert ms.last_data_at is None

# CandleRecord
cr = CandleRecord.from_dict({'bucket': '2026-02-17T12:00:00Z', 'market_ticker': 'KXBTC-24', 'open': 65, 'high': 70, 'low': 60, 'close': 68, 'volume': 500, 'trade_count': 50})
assert isinstance(cr.bucket, datetime)

# BillingStatus
bs = BillingStatus.from_dict({'tier': 'free', 'credits_total': 100, 'credits_used': 10, 'credits_remaining': 90, 'payg_enabled': False, 'billing_cycle_start': '2026-02-01T00:00:00Z'})
assert bs.credits_remaining == 90

print('OK')
"`
  </verify>
  <done>All ~20 response dataclasses importable and constructable. Datetime fields parsed. Field names match API JSON. No inheritance used (flat structures).</done>
</task>

</tasks>

<verification>
1. All model classes importable: `from kalshibook.models import ResponseMeta, OrderbookResponse, ...`
2. `ResponseMeta.from_headers()` correctly parses credit headers with -1 defaults for missing headers
3. All datetime string fields are parsed to `datetime` objects
4. All dataclasses are frozen (immutable) and use slots
5. Field names match `src/api/models.py` JSON keys exactly
6. No Pydantic imports -- pure stdlib dataclasses
</verification>

<success_criteria>
- models.py contains ~20 frozen dataclasses covering every API response shape
- Every dataclass has a from_dict() classmethod for JSON-to-object conversion
- All timestamp fields become datetime objects via parse_datetime()
- ResponseMeta.from_headers() handles missing credit headers gracefully (defaults to -1)
- No dataclass inheritance used (flat structures with duplicated fields)
- Zero runtime dependencies beyond stdlib + kalshibook._parsing
</success_criteria>

<output>
After completion, create `.planning/phases/09-models-exceptions-and-http-transport/09-02-SUMMARY.md`
</output>
